// Conversation history
let conversationHistory = [
    {
        role: 'system',
        content: 'You are a friendly English teacher helping middle school students practice English speaking and listening. Keep your responses encouraging, clear, and appropriate for middle school level. Use simple vocabulary and short sentences. Always respond in English.'
    }
];

// DOM elements
const recordBtn = document.getElementById('recordBtn');
const stopBtn = document.getElementById('stopBtn');
const status = document.getElementById('status');
const loading = document.getElementById('loading');
const conversationArea = document.getElementById('conversationArea');

// MediaRecorder and related variables
let mediaRecorder;
let audioChunks = [];
let isRecording = false;
let audioUnlocked = false;
let ttsAudioElement = null;

// Check if browser supports MediaRecorder
if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeã€Firefoxæˆ–Edgeæµè§ˆå™¨ã€‚');
}

// Unlock audio for iOS and WeChat
function unlockAudio() {
    console.log('Attempting to unlock audio...');
    
    // Function to unlock
    const unlock = () => {
        if (audioUnlocked) return;
        
        console.log('Audio unlock triggered');
        
        // Try to play a silent sound
        if (ttsAudioElement) {
            ttsAudioElement.src = 'data:audio/mpeg;base64,SUQzBAAAAAABEVRYWFgAAAAtAAADY29tbWVudABCaWdTb3VuZEJhbmsuY29tIC8gTGFTb25vdGhlcXVlLm9yZwBURU5DAAAAHQAAA1N3aXRjaCBQbHVzIMKpIE5DSCBTb2Z0d2FyZQBUSVQyAAAABgAAAzIyMzUAVFNTRQAAAA8AAANMYXZmNTcuODMuMTAwAAAAAAAAAAAAAAD/80DEAAAAA0gAAAAATEFNRTMuMTAwVVVVVVVVVVVVVUxBTUUzLjEwMFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQsRbAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQMSkAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV';
            ttsAudioElement.play().then(() => {
                console.log('Audio unlocked successfully');
                audioUnlocked = true;
            }).catch(e => {
                console.log('Audio unlock attempt:', e.message);
            });
        }
    };
    
    // Try to unlock on various events
    document.addEventListener('touchstart', unlock, { once: true });
    document.addEventListener('touchend', unlock, { once: true });
    document.addEventListener('click', unlock, { once: true });
    
    // WeChat specific unlock
    if (typeof WeixinJSBridge !== 'undefined') {
        console.log('WeChat detected, using WeixinJSBridge');
        WeixinJSBridge.invoke('getNetworkType', {}, unlock);
    } else {
        document.addEventListener('WeixinJSBridgeReady', () => {
            console.log('WeixinJSBridge ready');
            WeixinJSBridge.invoke('getNetworkType', {}, unlock);
        }, false);
    }
}

// Initialize
async function init() {
    try {
        // Get the audio element
        ttsAudioElement = document.getElementById('ttsAudio');
        if (!ttsAudioElement) {
            // Create audio element if it doesn't exist
            ttsAudioElement = document.createElement('audio');
            ttsAudioElement.id = 'ttsAudio';
            ttsAudioElement.preload = 'auto';
            ttsAudioElement.style.display = 'none';
            document.body.appendChild(ttsAudioElement);
        }
        
        // Unlock audio for iOS/WeChat
        unlockAudio();
        
        // Request microphone permission
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // Create MediaRecorder
        mediaRecorder = new MediaRecorder(stream);
        
        // Handle data available event
        mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
        };
        
        // Handle stop event
        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            audioChunks = [];
            
            // Process the audio
            await processAudio(audioBlob);
        };
        
        updateStatus('å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»"å¼€å§‹å½•éŸ³"æŒ‰é’®å¼€å§‹');
    } catch (error) {
        console.error('Initialization error:', error);
        updateStatus('åˆå§‹åŒ–å¤±è´¥: ' + error.message);
        alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·ç¡®ä¿å·²æˆäºˆéº¦å…‹é£æƒé™ã€‚');
    }
}

// Start recording
function startRecording() {
    if (!mediaRecorder) {
        alert('å½•éŸ³åŠŸèƒ½æœªåˆå§‹åŒ–ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚');
        return;
    }
    
    audioChunks = [];
    mediaRecorder.start();
    isRecording = true;
    
    recordBtn.disabled = true;
    stopBtn.disabled = false;
    updateStatus('ğŸ¤ æ­£åœ¨å½•éŸ³...');
}

// Stop recording
function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        
        recordBtn.disabled = false;
        stopBtn.disabled = true;
        updateStatus('å¤„ç†ä¸­...');
    }
}

// Process audio
async function processAudio(audioBlob) {
    try {
        showLoading(true);
        updateStatus('æ­£åœ¨è½¬æ¢è¯­éŸ³...');
        
        // Transcribe audio
        const transcription = await transcribeAudio(audioBlob);
        console.log('Transcription:', transcription);
        
        // Add user message to conversation
        addMessage('user', transcription);
        conversationHistory.push({
            role: 'user',
            content: transcription
        });
        
        updateStatus('æ­£åœ¨ç”Ÿæˆå›å¤...');
        
        // Get AI response
        const response = await getChatResponse(transcription);
        const aiMessage = response.choices[0].message.content;
        console.log('AI Response:', aiMessage);
        
        // Add AI message to conversation
        addMessage('assistant', aiMessage);
        conversationHistory.push({
            role: 'assistant',
            content: aiMessage
        });
        
        updateStatus('æ­£åœ¨æ’­æ”¾è¯­éŸ³...');
        
        // Speak the response
        await speakText(aiMessage);
        
        updateStatus('å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»"å¼€å§‹å½•éŸ³"ç»§ç»­å¯¹è¯');
        showLoading(false);
        
    } catch (error) {
        console.error('Processing error:', error);
        updateStatus('å¤„ç†å¤±è´¥: ' + error.message);
        showLoading(false);
        alert('å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚é”™è¯¯: ' + error.message);
    }
}

// Transcribe audio using AI Builders API
async function transcribeAudio(audioBlob) {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'recording.webm');
    
    const response = await fetch('/api/transcribe', {
        method: 'POST',
        body: formData
    });
    
    if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Transcription failed');
    }
    
    const data = await response.json();
    return data.text;
}

// Get chat response using AI Builders API
async function getChatResponse(message) {
    const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            message: message,
            history: conversationHistory
        })
    });
    
    if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Chat failed');
    }
    
    return await response.json();
}

// Speak text using backend TTS API with <audio> element (best mobile compatibility)
async function speakText(text) {
    return new Promise(async (resolve) => {
        try {
            console.log('Attempting backend TTS...');
            const response = await fetch('/api/tts', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ text: text })
            });

            if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                console.error('Backend TTS failed:', response.status, errorData);
                
                // Fallback to Web Speech Synthesis
                if (errorData.fallback || response.status >= 500) {
                    console.log('Using Web Speech Synthesis fallback...');
                    useFallbackTTS(text, resolve);
                    return;
                }
            }

            // Get audio blob
            const audioBlob = await response.blob();
            
            // Check if we got valid audio data
            if (audioBlob.size === 0) {
                console.error('Received empty audio blob, using fallback');
                useFallbackTTS(text, resolve);
                return;
            }

            console.log('Backend TTS succeeded, audio size:', audioBlob.size);
            
            // Use the dedicated audio element
            const audioUrl = URL.createObjectURL(audioBlob);
            
            if (!ttsAudioElement) {
                ttsAudioElement = document.getElementById('ttsAudio');
            }
            
            // Set up event listeners
            const onEnded = () => {
                console.log('Audio playback completed');
                URL.revokeObjectURL(audioUrl);
                ttsAudioElement.removeEventListener('ended', onEnded);
                ttsAudioElement.removeEventListener('error', onError);
                resolve();
            };
            
            const onError = (e) => {
                console.error('Audio playback error:', e);
                URL.revokeObjectURL(audioUrl);
                ttsAudioElement.removeEventListener('ended', onEnded);
                ttsAudioElement.removeEventListener('error', onError);
                
                // Try fallback
                console.log('Audio playback failed, trying fallback...');
                useFallbackTTS(text, resolve);
            };
            
            ttsAudioElement.addEventListener('ended', onEnded);
            ttsAudioElement.addEventListener('error', onError);
            
            // Set source and play
            ttsAudioElement.src = audioUrl;
            ttsAudioElement.load();
            
            try {
                await ttsAudioElement.play();
                console.log('Audio play started successfully');
            } catch (playError) {
                console.error('Audio play() failed:', playError);
                URL.revokeObjectURL(audioUrl);
                ttsAudioElement.removeEventListener('ended', onEnded);
                ttsAudioElement.removeEventListener('error', onError);
                
                console.log('Play failed, trying fallback...');
                useFallbackTTS(text, resolve);
            }

        } catch (error) {
            console.error('TTS error:', error);
            console.log('Exception caught, using fallback...');
            useFallbackTTS(text, resolve);
        }
    });
}

// Fallback TTS using Web Speech Synthesis API
function useFallbackTTS(text, resolve) {
    if ('speechSynthesis' in window) {
        console.log('Starting Web Speech Synthesis...');
        
        // Cancel any ongoing speech
        window.speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'en-US';
        utterance.rate = 0.9;
        utterance.pitch = 1.0;
        utterance.volume = 1.0;
        
        utterance.onstart = () => {
            console.log('Web Speech Synthesis started');
        };
        
        utterance.onend = () => {
            console.log('Web Speech Synthesis completed');
            resolve();
        };
        
        utterance.onerror = (e) => {
            console.error('Web Speech Synthesis error:', e);
            resolve();
        };
        
        // Small delay to ensure it works on mobile
        setTimeout(() => {
            window.speechSynthesis.speak(utterance);
        }, 100);
    } else {
        console.error('No TTS available');
        resolve();
    }
}

// Add message to conversation display
function addMessage(role, content) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `message ${role === 'user' ? 'user-message' : 'ai-message'}`;
    
    const label = role === 'user' ? 'ä½ ' : 'AI';
    const icon = role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–';
    
    messageDiv.innerHTML = `
        <div class="message-header">
            <span class="message-icon">${icon}</span>
            <strong>${label}:</strong>
        </div>
        <div class="message-content">${content}</div>
    `;
    
    conversationArea.appendChild(messageDiv);
    conversationArea.scrollTop = conversationArea.scrollHeight;
}

// Update status message
function updateStatus(message) {
    status.innerHTML = `<p>${message}</p>`;
}

// Show/hide loading indicator
function showLoading(show) {
    loading.style.display = show ? 'flex' : 'none';
}

// Event listeners
recordBtn.addEventListener('click', startRecording);
stopBtn.addEventListener('click', stopRecording);

// Initialize when page loads
document.addEventListener('DOMContentLoaded', init);
