// Conversation history
let conversationHistory = [
    {
        role: 'system',
        content: 'You are a friendly English teacher helping middle school students practice English speaking and listening. Keep your responses encouraging, clear, and appropriate for middle school level. Use simple vocabulary and short sentences. Always respond in English.'
    }
];

// DOM elements
const recordBtn = document.getElementById('recordBtn');
const stopBtn = document.getElementById('stopBtn');
const status = document.getElementById('status');
const loading = document.getElementById('loading');
const conversationArea = document.getElementById('conversationArea');

// MediaRecorder and related variables
let mediaRecorder;
let audioChunks = [];
let isRecording = false;

// Check if browser supports MediaRecorder
if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeã€Firefoxæˆ–Edgeæµè§ˆå™¨ã€‚');
}

// Initialize
async function init() {
    try {
        // Request microphone permission
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop()); // Stop immediately, we'll start recording when user clicks
        
        recordBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        
        updateStatus('å‡†å¤‡å°±ç»ª - Ready');
    } catch (error) {
        console.error('Error accessing microphone:', error);
        updateStatus('æ— æ³•è®¿é—®éº¦å…‹é£Ž - Cannot access microphone');
        alert('è¯·å…è®¸è®¿é—®éº¦å…‹é£Žæƒé™');
    }
}

// Start recording
async function startRecording() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        audioChunks = [];
        mediaRecorder = new MediaRecorder(stream, {
            mimeType: 'audio/webm;codecs=opus'
        });

        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };

        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            await processAudio(audioBlob);
            
            // Stop all tracks
            stream.getTracks().forEach(track => track.stop());
        };

        mediaRecorder.start();
        isRecording = true;
        
        recordBtn.classList.add('recording');
        recordBtn.disabled = true;
        stopBtn.disabled = false;
        updateStatus('æ­£åœ¨å½•éŸ³... - Recording...');
    } catch (error) {
        console.error('Error starting recording:', error);
        updateStatus('å½•éŸ³å¤±è´¥ - Recording failed');
        alert('æ— æ³•å¼€å§‹å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£Žæƒé™');
    }
}

// Stop recording
function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        
        recordBtn.classList.remove('recording');
        recordBtn.disabled = false;
        stopBtn.disabled = true;
        updateStatus('å¤„ç†ä¸­... - Processing...');
    }
}

// Process audio: transcribe -> chat -> speak
async function processAudio(audioBlob) {
    showLoading(true);
    
    try {
        // Step 1: Transcribe audio to text
        updateStatus('æ­£åœ¨è½¬å†™è¯­éŸ³... - Transcribing...');
        const transcription = await transcribeAudio(audioBlob);
        
        if (!transcription || !transcription.text) {
            throw new Error('è½¬å½•å¤±è´¥ - Transcription failed');
        }
        
        const userText = transcription.text.trim();
        if (!userText) {
            throw new Error('æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹ - No speech detected');
        }
        
        // Add user message to conversation
        addMessageToConversation('user', userText);
        conversationHistory.push({
            role: 'user',
            content: userText
        });
        
        // Step 2: Get response from AI
        updateStatus('æ­£åœ¨ç”Ÿæˆå›žå¤... - Generating response...');
        const aiResponse = await getAIResponse();
        
        if (!aiResponse || !aiResponse.choices || !aiResponse.choices[0]) {
            throw new Error('AIå›žå¤å¤±è´¥ - AI response failed');
        }
        
        const assistantText = aiResponse.choices[0].message.content.trim();
        
        // Add assistant message to conversation
        addMessageToConversation('assistant', assistantText);
        conversationHistory.push({
            role: 'assistant',
            content: assistantText
        });
        
        // Step 3: Speak the response
        updateStatus('æ­£åœ¨æœ—è¯»å›žå¤... - Speaking response...');
        await speakText(assistantText);
        
        updateStatus('å®Œæˆï¼å¯ä»¥ç»§ç»­å½•éŸ³ - Done! You can continue recording');
    } catch (error) {
        console.error('Error processing audio:', error);
        updateStatus('å¤„ç†å¤±è´¥ - Processing failed: ' + error.message);
        alert('å¤„ç†å¤±è´¥ï¼š' + error.message);
    } finally {
        showLoading(false);
    }
}

// Transcribe audio using API
async function transcribeAudio(audioBlob) {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'recording.webm');
    
    const response = await fetch('/api/transcribe', {
        method: 'POST',
        body: formData
    });
    
    if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Transcription failed');
    }
    
    return await response.json();
}

// Get AI response using API
async function getAIResponse() {
    const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            messages: conversationHistory
        })
    });
    
    if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Chat failed');
    }
    
    return await response.json();
}

// Speak text using backend TTS API (more reliable on mobile devices)
function speakText(text) {
    return new Promise((resolve, reject) => {
        // Use backend TTS API for better mobile compatibility
        fetch('/api/tts', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ text: text })
        })
        .then(response => {
            if (!response.ok) {
                throw new Error('TTS request failed');
            }
            return response.blob();
        })
        .then(audioBlob => {
            // Create audio element and play
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);
            
            audio.onended = () => {
                URL.revokeObjectURL(audioUrl);
                resolve();
            };
            
            audio.onerror = (error) => {
                console.error('Audio playback error:', error);
                URL.revokeObjectURL(audioUrl);
                resolve(); // Don't fail the whole process
            };
            
            // Play audio
            audio.play().catch(error => {
                console.error('Error playing audio:', error);
                URL.revokeObjectURL(audioUrl);
                resolve(); // Don't fail if play fails
            });
        })
        .catch(error => {
            console.error('TTS API error:', error);
            // Fallback to Web Speech Synthesis if backend fails
            fallbackToWebSpeech(text).then(resolve).catch(() => resolve());
        });
    });
}

// Fallback to Web Speech Synthesis API (for desktop browsers)
function fallbackToWebSpeech(text) {
    return new Promise((resolve, reject) => {
        if (!('speechSynthesis' in window)) {
            resolve();
            return;
        }
        
        window.speechSynthesis.cancel();
        
        setTimeout(() => {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            utterance.rate = 0.9;
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            let resolved = false;
            
            utterance.onend = () => {
                if (!resolved) {
                    resolved = true;
                    resolve();
                }
            };
            
            utterance.onerror = () => {
                if (!resolved) {
                    resolved = true;
                    resolve();
                }
            };
            
            try {
                window.speechSynthesis.speak(utterance);
                setTimeout(() => {
                    if (!resolved) {
                        resolved = true;
                        resolve();
                    }
                }, Math.max(text.length * 100, 5000));
            } catch (error) {
                resolve();
            }
        }, 100);
    });
}

// Add message to conversation display
function addMessageToConversation(role, text) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `message ${role}`;
    
    const header = document.createElement('div');
    header.className = 'message-header';
    header.textContent = role === 'user' ? 'ðŸ‘¤ ä½  (You)' : 'ðŸ¤– AIè€å¸ˆ (AI Teacher)';
    
    const content = document.createElement('div');
    content.className = 'message-content';
    if (role === 'assistant') {
        content.classList.add('english');
    }
    content.textContent = text;
    
    messageDiv.appendChild(header);
    messageDiv.appendChild(content);
    
    // Add play button for assistant messages (works on all devices)
    if (role === 'assistant') {
        const playButton = document.createElement('button');
        playButton.className = 'play-btn';
        playButton.innerHTML = 'ðŸ”Š æ’­æ”¾å£°éŸ³';
        playButton.title = 'ç‚¹å‡»æ’­æ”¾è¿™æ®µæ–‡å­—';
        playButton.onclick = () => {
            playButton.disabled = true;
            playButton.innerHTML = 'â¸ï¸ æ’­æ”¾ä¸­...';
            speakText(text).then(() => {
                playButton.disabled = false;
                playButton.innerHTML = 'ðŸ”Š æ’­æ”¾å£°éŸ³';
            });
        };
        messageDiv.appendChild(playButton);
    }
    
    // Remove welcome message if it exists
    const welcomeMsg = conversationArea.querySelector('.welcome-message');
    if (welcomeMsg) {
        welcomeMsg.remove();
    }
    
    conversationArea.appendChild(messageDiv);
    conversationArea.scrollTop = conversationArea.scrollHeight;
}

// Update status message
function updateStatus(message) {
    status.textContent = message;
}

// Show/hide loading indicator
function showLoading(show) {
    loading.style.display = show ? 'block' : 'none';
}

// Load version info - version is embedded in HTML, no API call needed
function loadVersion() {
    // Version is already embedded in HTML, no need to fetch from API
    // This avoids 404 errors and makes the app more reliable
    const versionInfo = document.getElementById('versionInfo');
    if (versionInfo && !versionInfo.textContent || versionInfo.textContent === 'ç‰ˆæœ¬åŠ è½½ä¸­...') {
        // If somehow the version wasn't set, it's already in HTML
        // Just ensure it's displayed
        console.log('Version loaded from HTML');
    }
}

// Initialize when page loads
init();
loadVersion();

